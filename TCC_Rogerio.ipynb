{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRABALHO DE CONCLUSÃO DE CURSO - TCC\n",
    "# ------------------------------------\n",
    "# Rogerio Carlos Vieira Maciel\n",
    "# Curso de Especialização em Ciência de Dados e Big Data\n",
    "# PUC Minas - abril de 2021\n",
    "\n",
    "# Carrega as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time, calendar\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# Define parâmetros gerais do ambiente\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Define alguns parâmetros iniciais gerais\n",
    "# ----------------------------------------\n",
    "\n",
    "# Período para análises exploratórias dos dados\n",
    "ANALISES_ANO_INICIAL = 2013\n",
    "ANALISES_ANO_FINAL = 2020\n",
    "\n",
    "# Período para construção do modelo de aprendizado de máquina\n",
    "MODELO_ANO_INICIAL = 2018\n",
    "MODELO_ANO_FINAL = 2019\n",
    "\n",
    "# Carga dos datasets\n",
    "UTILIZAR_DATASET_REDUZIDO_PARA_ANALISES = True\n",
    "CARREGAR_DATASETS_DO_REPOSITORIO_NUVEM = True\n",
    "GRAVAR_DATASET_AMOSTRAS_IMP_COMPLETA = False\n",
    "AMOSTRAS_IMP_COMPLETA_LOCAL = 250000\n",
    "CAMINHO_AMOSTRAS_IMP_COMPLETA_LOCAL = 'd:\\\\datasets\\\\IMP_COMPLETA_AMOSTRAS.csv'\n",
    "\n",
    "# Geração do dataset base para os modelos de aprendizado de máquina\n",
    "UTILIZAR_DATASET_BASE_PRE_GRAVADO = True\n",
    "GRAVAR_DATASET_BASE = False\n",
    "AMOSTRAS_DATASET_BASE_PRE_GRAVADO = 100000\n",
    "CAMINHO_DATASET_BASE_LOCAL = 'd:\\\\datasets\\\\DF_BASE.csv'\n",
    "\n",
    "# Estrutura de dados para armazenar parâmetros do modelo preditivo\n",
    "class Lista_Param_Modelo:\n",
    "    l_co_pais = None\n",
    "    l_co_urf = None\n",
    "    l_co_via = None\n",
    "    l_sg_uf_ncm = None\n",
    "    l_ncm_6 = None\n",
    "    l_ncm_4 = None\n",
    "    l_ncm = None \n",
    "    l_completa_co_pais = None\n",
    "    l_completa_co_urf = None\n",
    "    l_completa_co_via = None\n",
    "    l_completa_sg_uf_ncm = None\n",
    "    l_completa_ncm_6 = None\n",
    "    l_completa_ncm_4 = None\n",
    "    l_completa_ncm = None \n",
    "    opcao_NCM=4\n",
    "    qtd_amostras = 1000\n",
    "    proporcao_teste=0.2\n",
    "    imprimir_parametros=False\n",
    "    imprimir_resultados=True\n",
    "    otimizar_com_grid_search = False\n",
    "    versao='0.0.0'\n",
    "    \n",
    "# Semente para o gerador de números aleatórios\n",
    "i_SEED = 12345678\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Carga dos datasets utilizados no trabalho\n",
    "# Item 3.1.1 do TCC\n",
    "# -----------------\n",
    "\n",
    "if CARREGAR_DATASETS_DO_REPOSITORIO_NUVEM:\n",
    "    if UTILIZAR_DATASET_REDUZIDO_PARA_ANALISES:\n",
    "        df_orig_imp_completa = pd.read_csv(\n",
    "            'https://raw.githubusercontent.com/rogmac/TCC/main/datasets/IMP_COMPLETA_AMOSTRAS.csv',\n",
    "            sep=';')\n",
    "    else:\n",
    "        df_orig_imp_completa = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\IMP_COMPLETA.csv',\n",
    "                                   sep=';')\n",
    "    \n",
    "    df_orig_dolar_mensal = pd.read_csv(\n",
    "        'https://raw.githubusercontent.com/rogmac/TCC/main/datasets/DOLAR_MENSAL.csv',\n",
    "         sep=';', dtype={'ANO_MES': np.str}, decimal=',')\n",
    "    df_orig_ncm = pd.read_csv('https://raw.githubusercontent.com/rogmac/TCC/main/datasets/NCM.csv',\n",
    "         sep=';',encoding='latin1')\n",
    "    df_orig_ncm_sh = pd.read_csv('https://raw.githubusercontent.com/rogmac/TCC/main/datasets/NCM_SH.csv',\n",
    "         sep=';', encoding='latin1')\n",
    "    df_orig_pais = pd.read_csv('https://raw.githubusercontent.com/rogmac/TCC/main/datasets/PAIS.csv',\n",
    "         sep=';',encoding='latin1')\n",
    "    df_orig_pais_bloco = pd.read_csv(\n",
    "        'https://raw.githubusercontent.com/rogmac/TCC/main/datasets/PAIS_BLOCO.csv',\n",
    "         sep=';', encoding='latin1')\n",
    "    df_orig_uf = pd.read_csv('https://raw.githubusercontent.com/rogmac/TCC/main/datasets/UF.csv',\n",
    "         sep=';',encoding='latin1')\n",
    "    df_orig_via = pd.read_csv('https://raw.githubusercontent.com/rogmac/TCC/main/datasets/VIA.csv',\n",
    "         sep=';',encoding='latin1')\n",
    "    df_orig_urf = pd.read_csv('https://raw.githubusercontent.com/rogmac/TCC/main/datasets/URF.csv',\n",
    "         sep=';',encoding='latin1')\n",
    "else:\n",
    "    # Carrega os datasets originais (disponibilizados nos sites do Ministério da Economia e do IPEA)\n",
    "    #  (para o dataset principal, oferece a possibilidade de carregar uma amostra reduzida)\n",
    "    if UTILIZAR_DATASET_REDUZIDO_PARA_ANALISES:\n",
    "        df_orig_imp_completa = pd.read_csv(filepath_or_buffer=CAMINHO_AMOSTRAS_IMP_COMPLETA_LOCAL,\n",
    "                                           sep=';')\n",
    "    else:\n",
    "        df_orig_imp_completa = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\IMP_COMPLETA.csv',\n",
    "                                           sep=';')\n",
    "    \n",
    "    df_orig_dolar_mensal = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\DOLAR_MENSAL.csv',sep=';', \n",
    "                                           dtype={'ANO_MES': np.str}, decimal=',')\n",
    "    df_orig_ncm = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\NCM.csv',sep=';',encoding='latin1')\n",
    "    df_orig_ncm_sh = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\NCM_SH.csv',sep=';',\n",
    "                                            encoding='latin1')\n",
    "    df_orig_pais = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\PAIS.csv',sep=';',encoding='latin1')\n",
    "    df_orig_pais_bloco = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\PAIS_BLOCO.csv',sep=';',\n",
    "                                            encoding='latin1')\n",
    "    df_orig_uf = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\UF.csv',sep=';',encoding='latin1')\n",
    "    df_orig_via = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\VIA.csv',sep=';',encoding='latin1')\n",
    "    df_orig_urf = pd.read_csv(filepath_or_buffer='d:\\\\datasets\\\\URF.csv',sep=';',encoding='latin1')\n",
    "\n",
    "    \n",
    "# Registra as quantidades de linhas e colunas dos datasets carregados\n",
    "print('Quantidades de linhas e colunas dos datasets carregados:')\n",
    "print(f'    IMP_COMPLETA - {df_orig_imp_completa.shape[0]} linhas e '\n",
    "      f'{df_orig_imp_completa.shape[1]} colunas' )\n",
    "print(f'    DOLAR_MENSAL - {df_orig_dolar_mensal.shape[0]} linhas e '\n",
    "      f'{df_orig_dolar_mensal.shape[1]} colunas' )\n",
    "print(f'    NCM - {df_orig_ncm.shape[0]} linhas e '\n",
    "      f'{df_orig_ncm.shape[1]} colunas' )\n",
    "print(f'    NCM_SH - {df_orig_ncm_sh.shape[0]} linhas e {df_orig_ncm_sh.shape[1]} colunas' )\n",
    "print(f'    PAIS - {df_orig_pais.shape[0]} linhas e {df_orig_pais.shape[1]} colunas' )\n",
    "print(f'    PAIS_BLOCO - {df_orig_pais_bloco.shape[0]} linhas e '\n",
    "      f'{df_orig_pais_bloco.shape[1]} colunas' )\n",
    "print(f'    UF - {df_orig_uf.shape[0]} linhas e {df_orig_uf.shape[1]} colunas' )\n",
    "print(f'    VIA - {df_orig_via.shape[0]} linhas e {df_orig_via.shape[1]} colunas' )\n",
    "print(f'    URF - {df_orig_urf.shape[0]} linhas e {df_orig_urf.shape[1]} colunas' )\n",
    "\n",
    "# Se desejado, grava uma amostra dos dados localmente, para uso no repositório\n",
    "if GRAVAR_DATASET_AMOSTRAS_IMP_COMPLETA:\n",
    "    # Seleciona amostras aleatórias, para gravar no disco\n",
    "    df_temp = df_orig_imp_completa[(df_orig_imp_completa['CO_ANO'] >= ANALISES_ANO_INICIAL) & \n",
    "                                   (df_orig_imp_completa['CO_ANO'] <= ANALISES_ANO_FINAL)]\n",
    "    np.random.seed(i_SEED)\n",
    "    indices = np.random.choice(df_temp.shape[0], replace = False, size=AMOSTRAS_IMP_COMPLETA_LOCAL)\n",
    "    df_temp = df_temp.iloc[indices]\n",
    "    df_temp.to_csv(CAMINHO_AMOSTRAS_IMP_COMPLETA_LOCAL, sep=';', index=False)\n",
    "    del df_temp\n",
    "\n",
    "df_orig_imp_completa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Processamento inicial dos dados carregados\n",
    "\n",
    "\n",
    "# Cria o dataframe de trabalho de dados agregados de importações (df_imp_completa)\n",
    "# Separa somente o período desejado para análise exploratória\n",
    "# Item 3.1.2 do TCC\n",
    "# -----------------\n",
    "df_imp_completa = df_orig_imp_completa[(df_orig_imp_completa['CO_ANO'] >= ANALISES_ANO_INICIAL)\n",
    "                                       & (df_orig_imp_completa['CO_ANO'] <= ANALISES_ANO_FINAL)]\n",
    "\n",
    "\n",
    "# Cria o dataframe de trabalho para cotações de dólar (df_dolar_mensal)\n",
    "# Formata as colunas para individualizar ano  e mês\n",
    "# Separa somente o período desejado para análise exploratória\n",
    "# Item 3.1.2 do TCC\n",
    "# -----------------\n",
    "df_dolar_mensal = df_orig_dolar_mensal.filter(['ANO_MES','ANO_MES','VALOR'], axis=1)\n",
    "df_dolar_mensal.set_axis(['COL1', 'COL2', 'VALOR'], axis='columns', inplace=True)\n",
    "df_dolar_mensal['COL1'] = df_dolar_mensal['COL1'].astype(str).str[:4]\n",
    "df_dolar_mensal['COL2'] = df_dolar_mensal['COL2'].astype(str).str.slice(5, 8)\n",
    "df_dolar_mensal.set_axis(['CO_ANO', 'CO_MES', 'VALOR'], axis='columns', inplace=True)\n",
    "df_dolar_mensal['CO_ANO'] = pd.to_numeric(df_dolar_mensal['CO_ANO'])\n",
    "df_dolar_mensal['CO_MES'] = pd.to_numeric(df_dolar_mensal['CO_MES'])\n",
    "df_dolar_mensal = df_dolar_mensal[(df_dolar_mensal['CO_ANO'] >= ANALISES_ANO_INICIAL) \n",
    "                                  & (df_dolar_mensal['CO_ANO'] <= ANALISES_ANO_FINAL)]\n",
    "\n",
    "\n",
    "# Verifica se existem linhas duplicadas no dataset IMP_COMPLETA\n",
    "# Item 3.1.3 do TCC\n",
    "# -----------------\n",
    "duplicados=[]\n",
    "for ano in df_imp_completa['CO_ANO'].unique():\n",
    "    # separa por ano para facilitar o tratamento, caso haja itens duplicados\n",
    "    df_anual = df_imp_completa[df_imp_completa['CO_ANO']==ano]\n",
    "    linhas_duplicadas_ano = (df_anual.duplicated().sum())\n",
    "    duplicados.append(linhas_duplicadas_ano)\n",
    "print(f'Total de linhas duplicadas no dataset DF_IMP_COMPLETA: {sum(duplicados)}\\n')\n",
    "del df_anual\n",
    "\n",
    "# Verifica se existem linhas duplicadas no dataset DOLAR_MENSAL\n",
    "# Item 3.1.3 do TCC\n",
    "# -----------------\n",
    "print(f'Total de linhas duplicadas em DF_DOLAR_MENSAL: {df_dolar_mensal.duplicated().sum()}\\n')\n",
    "\n",
    "\n",
    "# Verifica existência de valores ausentes (missing values) no dataset IMP_COMPLETA\n",
    "# Item 3.1.4 do TCC\n",
    "# -----------------\n",
    "print('Quantidade de valores ausentes em cada coluna do dataset DF_IMP_COMPLETA:')\n",
    "print('    CO_ANO: {v}'.format(v=df_imp_completa['CO_ANO'].isna().sum()))\n",
    "print('    CO_MES: {v}'.format(v=df_imp_completa['CO_MES'].isna().sum()))\n",
    "print('    CO_NCM: {v}'.format(v=df_imp_completa['CO_NCM'].isna().sum()))\n",
    "print('    CO_UNID: {v}'.format(v=df_imp_completa['CO_UNID'].isna().sum()))\n",
    "print('    CO_PAIS: {v}'.format(v=df_imp_completa['CO_PAIS'].isna().sum()))\n",
    "print('    SG_UF_NCM: {v}'.format(v=df_imp_completa['SG_UF_NCM'].isna().sum()))\n",
    "print('    CO_VIA: {v}'.format(v=df_imp_completa['CO_VIA'].isna().sum()))\n",
    "print('    CO_URF: {v}'.format(v=df_imp_completa['CO_URF'].isna().sum()))\n",
    "print('    QT_ESTAT: {v}'.format(v=df_imp_completa['QT_ESTAT'].isna().sum()))\n",
    "print('    KG_LIQUIDO: {v}'.format(v=df_imp_completa['KG_LIQUIDO'].isna().sum()))\n",
    "print('    VL_FOB: {v}'.format(v=df_imp_completa['VL_FOB'].isna().sum()))\n",
    "print('')\n",
    "\n",
    "\n",
    "# Verifica existência de valores ausentes (missing values) no dataset DOLAR_MENSAL\n",
    "# Item 3.1.4 do TCC\n",
    "# -----------------\n",
    "print('Quantidade de valores ausentes em cada coluna do dataset DF_DOLAR_MENSAL:')\n",
    "print('    CO_ANO: {v}'.format(v=df_dolar_mensal['CO_ANO'].isna().sum()))\n",
    "print('    CO_MES: {v}'.format(v=df_dolar_mensal['CO_MES'].isna().sum()))\n",
    "print('    VALOR: {v}'.format(v=df_dolar_mensal['VALOR'].isna().sum()))\n",
    "print('')\n",
    "\n",
    "\n",
    "# Verifica se os códigos usados nas colunas de IMP_COMPLETA existem nas tabelas auxiliares\n",
    "# Item 3.2 do TCC\n",
    "# ---------------\n",
    "def verifica_ausencias (df_coluna_valores_imp, df_coluna_dataset_auxiliar):\n",
    "    # função para avaliar se os valores únicos de uma coluna existem na coluna auxiliar\n",
    "    i_total_ausentes=0\n",
    "    for item in df_coluna_valores_imp.unique():\n",
    "        if item not in df_coluna_dataset_auxiliar.values:\n",
    "            i_total_ausentes += 1\n",
    "    return i_total_ausentes, df_coluna_valores_imp.unique().shape[0]\n",
    "    \n",
    "print('Quantidade de códigos usados em DF_IMP_COMPLETA que NÃO foram localizados '\n",
    "      'nos datasets auxiliares:')\n",
    "\n",
    "(itens_ausentes, total_de_itens) = verifica_ausencias ( df_imp_completa['CO_NCM'] \n",
    "                                                       , df_orig_ncm['CO_NCM'])\n",
    "print(f'    coluna CO_NCM, verificada junto ao dataset NCM: {itens_ausentes} ausentes, '\n",
    "      f'de um total de {total_de_itens} itens únicos' )\n",
    "\n",
    "(itens_ausentes, total_de_itens) = verifica_ausencias ( df_imp_completa['CO_PAIS'] , \n",
    "                                                       df_orig_pais['CO_PAIS'])\n",
    "print(f'    coluna CO_PAIS, verificada junto ao dataset PAIS: {itens_ausentes} ausentes, '\n",
    "      f'de um total de {total_de_itens} itens únicos' )\n",
    "\n",
    "(itens_ausentes, total_de_itens) = verifica_ausencias ( df_imp_completa['SG_UF_NCM'] , \n",
    "                                                       df_orig_uf['SG_UF'])\n",
    "print(f'    coluna SG_UF_NCM, verificada junto ao dataset UF: {itens_ausentes} ausentes, '\n",
    "      f'de um total de {total_de_itens} itens únicos' )\n",
    "\n",
    "(itens_ausentes, total_de_itens) = verifica_ausencias ( df_imp_completa['CO_VIA'] , \n",
    "                                                       df_orig_via['CO_VIA'])\n",
    "print(f'    coluna CO_VIA, verificada junto ao dataset UF: {itens_ausentes} ausentes, '\n",
    "      f'de um total de {total_de_itens} itens únicos' )\n",
    "\n",
    "(itens_ausentes, total_de_itens) = verifica_ausencias ( df_imp_completa['CO_URF'] , \n",
    "                                                       df_orig_urf['CO_URF'])\n",
    "print(f'    coluna CO_URF, verificada junto ao dataset URF: {itens_ausentes} ausentes, '\n",
    "      f'de um total de {total_de_itens} itens únicos' )\n",
    "print('')\n",
    "\n",
    "\n",
    "# Libera as variáveis que não serão mais utilizadas\n",
    "del df_orig_imp_completa\n",
    "del df_orig_dolar_mensal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Avalia se as combinações entre \"NCM\" e \"Unidade estatística\" são únicas a cada ano\n",
    "# Item 3.3.1 do TCC\n",
    "# -----------------\n",
    "print('Avalia se as combinações entre NCM e Unidade estatística são únicas em cada ano:')\n",
    "for ano in df_imp_completa['CO_ANO'].unique():\n",
    "    df_anual = df_imp_completa[df_imp_completa['CO_ANO']==ano]\n",
    "    df_na = df_anual['CO_NCM'].astype(str) + ' - ' + df_anual['CO_UNID'].astype(str)\n",
    "    total_ncm_unicas = df_anual['CO_NCM'].unique().shape[0]\n",
    "    total_combinacoes_unicas = df_na.unique().shape[0]\n",
    "    divergencias = total_combinacoes_unicas - total_ncm_unicas\n",
    "    print(f'  {ano}: {divergencias} divergências ({total_ncm_unicas} NCM únicas e '\n",
    "          f'{total_combinacoes_unicas} combinações únicas de NCM e Unidade estatística)')\n",
    "del df_anual\n",
    "del df_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tendo em vista a ausência de divergências, remove as colunas CO_UNID e QT_ESTAT\n",
    "# Item 3.3.1 do TCC\n",
    "# -----------------\n",
    "df_imp_completa = df_imp_completa.drop(['CO_UNID', 'QT_ESTAT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trata os valores de VL_FOB e KG_LIQUIDO iguais a zero (modifica para um)\n",
    "# Item 3.3.2 do TCC\n",
    "# -----------------\n",
    "linhas_fob_zero = df_imp_completa['VL_FOB'][df_imp_completa['VL_FOB']==0].shape[0]\n",
    "linhas_kg_zero = df_imp_completa['KG_LIQUIDO'][df_imp_completa['KG_LIQUIDO']==0].shape[0]\n",
    "print(f'Linhas com VL_FOB igual a zero: {linhas_fob_zero}')\n",
    "print(f'Linhas com KG_LIQUIDO igual a zero: {linhas_kg_zero}')\n",
    "df_imp_completa['VL_FOB'][df_imp_completa['VL_FOB']==0] = 1\n",
    "df_imp_completa['KG_LIQUIDO'][df_imp_completa['KG_LIQUIDO']==0] = 1\n",
    "\n",
    "# Converte as colunas VL_FOB e KG_LIQUIDO para o tipo float\n",
    "df_imp_completa['VL_FOB'] = df_imp_completa['VL_FOB'].astype(float)\n",
    "df_imp_completa['KG_LIQUIDO'] = df_imp_completa['KG_LIQUIDO'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise e tratamento de outliers\n",
    "# Item 3.4 do TCC\n",
    "#----------------\n",
    "\n",
    "f = plt.figure(figsize=[10,3])\n",
    "fig = sns.boxplot(data=df_imp_completa,x=df_imp_completa['VL_FOB'])\n",
    "fig.set_xscale('log')\n",
    "fig.set_title('Análise de outliers na coluna Valor FOB')\n",
    "Q1=df_imp_completa['VL_FOB'].quantile(0.25)\n",
    "Q3=df_imp_completa['VL_FOB'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "print(f'Análise de outliers no dataset IMP_COMPLETA, coluna Valor FOB:')\n",
    "print(f'Limites para outliers: inferior: {lim_inf}, superior: {lim_sup}')\n",
    "print(f'Quartil 25%: {Q1}')\n",
    "\n",
    "f = plt.figure(figsize=[10,3])\n",
    "fig = sns.boxplot(data=df_imp_completa,x=df_imp_completa['KG_LIQUIDO'])\n",
    "fig.set_xscale('log')\n",
    "fig.set_title('Análise de outliers na coluna Valor KG_LIQUIDO')\n",
    "Q1=df_imp_completa['KG_LIQUIDO'].quantile(0.25)\n",
    "Q3=df_imp_completa['KG_LIQUIDO'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "print(f'Análise de outliers no dataset IMP_COMPLETA, coluna Valor KG_LIQUIDO:')\n",
    "print(f'Limites para outliers: inferior: {lim_inf}, superior: {lim_sup}')\n",
    "print(f'Quartil 25%: {Q1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Integração entre os datasets IMP_COMPLETA e DOLAR_MENSAL\n",
    "# Atribui a cotação mensal do dólar a uma nova coluna no dataset IMP_COMPLETA\n",
    "# Item 3.5 do TCC\n",
    "# ---------------\n",
    "df_imp_completa['VALOR_DOLAR']=0\n",
    "for ano in df_imp_completa['CO_ANO'].unique():\n",
    "    for mes in range (1,13):\n",
    "        cotacao = df_dolar_mensal.loc[(df_dolar_mensal['CO_ANO'] == ano) & \n",
    "                                      (df_dolar_mensal['CO_MES'] == mes)]\n",
    "        df_imp_completa['VALOR_DOLAR'][(df_imp_completa['CO_ANO'] == ano) & \n",
    "                                       (df_imp_completa['CO_MES'] == mes)] = cotacao['VALOR'].values[0]\n",
    "              \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estrutura final do dataset IMP_COMPLETA\n",
    "# Item 3.6 do TCC\n",
    "# ---------------\n",
    "df_imp_completa.reset_index(inplace=True, drop=True)\n",
    "print('Estrutura final do dataset IMP_COMPLETA, após as validações e modificações realizadas')\n",
    "print(f'  Quantidade de linhas do dataset IMP_COMPLETA: {df_imp_completa.shape[0]}; '\n",
    "      f'colunas: {df_imp_completa.shape[1]}')\n",
    "df_imp_completa.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Avaliação da evolução do valor FOB e do peso líquido das importações, por ano\n",
    "# Comparação entre a relação FOB/KG e a cotação do dólar norte-americano\n",
    "# Item 4.1 do TCC\n",
    "#----------------\n",
    "\n",
    "# Prepara o dataset contendo os valores agregados por ano\n",
    "df_valores_anuais = df_imp_completa.groupby(['CO_ANO']).agg({'VL_FOB': ['sum'], 'KG_LIQUIDO': ['sum'], \n",
    "                            'VALOR_DOLAR': ['mean']}).sort_values(by=['CO_ANO'])\n",
    "df_valores_anuais.columns=['Valor FOB (anual)','Peso líquido (anual)', \n",
    "                           'Cotação média do dólar (anual)']\n",
    "df_valores_anuais['Relação FOB/Kg'] = ( df_valores_anuais['Valor FOB (anual)'] /\n",
    "                                       df_valores_anuais['Peso líquido (anual)'] )\n",
    "df_valores_anuais = df_valores_anuais[['Valor FOB (anual)','Relação FOB/Kg',\n",
    "                                       'Peso líquido (anual)','Cotação média do dólar (anual)']]\n",
    "titulo = (f'Evolução do valor FOB, peso líquido, relação FOB/Kg e '\n",
    "         f'cotação do dólar - {df_valores_anuais.index.min()} a {df_valores_anuais.index.max()}')\n",
    "df_valores_anuais['Valor FOB (anual)'] = df_valores_anuais['Valor FOB (anual)'] / 10**9\n",
    "df_valores_anuais['Peso líquido (anual)'] = df_valores_anuais['Peso líquido (anual)'] / 10**9\n",
    "\n",
    "# Plota o gráfico com os comparativos anuais\n",
    "(ax1, ax2), (ax3,ax4) = df_valores_anuais.plot(subplots=True, layout=(2,2),figsize=(15, 6), \n",
    "                                               xlabel='Ano', title=titulo, sharex=False)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "axz = ax1.set_title('Valor FOB (bilhões de USD)')\n",
    "axz = ax3.set_title('Peso líquido (milhões de toneladas)')\n",
    "axz = ax2.set_title('Relação FOB/Kg')\n",
    "axz = ax4.set_title('Cotação do dólar (R$/USD)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparação entre alguns casos de sazonalidade nas importações\n",
    "# Item 4.2 do TCC\n",
    "# ---------------\n",
    "\n",
    "def graficos_comparativos_sazonalidade (df_filtrado, titulo, ano_inicio, ano_fim):\n",
    "    \"\"\" Função para realizar a comparação de sazonalidade de forma genérica\n",
    "        Recebe como entrada o dataset contendo apenas as linhas de interesse,\n",
    "          período (ano de início e fim) e título para o gráfico\n",
    "        Plota os gráficos individualizados (por ano) e o acumulado de cada mês\n",
    "    \"\"\"\n",
    "    ano = ano_inicio\n",
    "    df_imp_ano = df_filtrado[df_filtrado['CO_ANO']==ano]\n",
    "    df_soma_mes = df_imp_ano.groupby(['CO_MES']).agg({'VL_FOB': ['sum'] }).sort_values(by=['CO_MES'])\n",
    "    df_soma_mes.columns=[ano]\n",
    "    df_valores_mensais = df_soma_mes\n",
    "    ano = ano +1\n",
    "    while ano <= ano_fim:\n",
    "        df_imp_ano = df_filtrado[df_filtrado['CO_ANO']==ano]\n",
    "        df_soma_mes=df_imp_ano.groupby(['CO_MES']).agg({'VL_FOB':['sum'] }).sort_values(by=['CO_MES'])\n",
    "        df_soma_mes.columns=[ano]\n",
    "        df_valores_mensais = pd.concat([df_valores_mensais, df_soma_mes], axis=1)\n",
    "        ano = ano +1\n",
    "\n",
    "    # Plota gráficos para cada ano\n",
    "    fig = df_valores_mensais.plot(kind='bar', subplots=True, layout=(4,2),figsize=(15, 6), \n",
    "                                  xlabel='Mês', title =f'{titulo} - {ano_inicio} a {ano_fim}')   \n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    # Plota gráfico acumulado (em barras) para o volume, agrupado por mês\n",
    "    fig = df_valores_mensais.plot.bar(stacked=True, figsize=(12,4), \n",
    "                                title=f'{titulo} - Valores FOB USD agrupados por mês', xlabel='Mês')\n",
    "\n",
    "\n",
    "# Gráfico para NCM 31052000 (fertilizantes) com entrada pelo Porto de Santos (817800)\n",
    "graficos_comparativos_sazonalidade (df_imp_completa[(df_imp_completa['CO_URF']==817800) & \n",
    "                                                    (df_imp_completa['CO_NCM']==31052000)],\n",
    "                                    'Análise comparativa para fertilizantes, Porto de Santos', \n",
    "                                    ANALISES_ANO_INICIAL+2, ANALISES_ANO_FINAL)\n",
    "\n",
    "# Gráfico para NCM 8093010 (pêssegos) originários da Espanha (245)\n",
    "graficos_comparativos_sazonalidade (df_imp_completa[(df_imp_completa['CO_NCM']==8093010) & \n",
    "                                                    (df_imp_completa['CO_PAIS']==245)], \n",
    "                                    'Análise comparativa para pêssegos, originários da Espanha', \n",
    "                                    ANALISES_ANO_INICIAL+2, ANALISES_ANO_FINAL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Análise da participação (percentual do FOB total) dos itens de cada coluna de IMP_COMPLETA\n",
    "# (país de origem, via de transporte, unidade desembarque, unidade da federação, NCM)\n",
    "# Calcula quantos itens são necessários para se atingir um mínimo percentual de cobertura\n",
    "# Item 4.3 do TCC\n",
    "# ---------------\n",
    "\n",
    "\n",
    "# Limiares iniciais para estudo da participação dos itens em cada coluna\n",
    "LIMIAR_PAISES = 80\n",
    "LIMIAR_URF = 80\n",
    "LIMIAR_VIA = 80\n",
    "LIMIAR_UF = 80\n",
    "LIMIAR_NCM = 80\n",
    "\n",
    "# Prepara colunas nos datasets para os códigos de NCM com 6 dígitos (subposição) e 4 dígitos (posição)\n",
    "df_imp_completa['NCM_6'] = df_imp_completa['CO_NCM'].astype(str).str.zfill(8).str[0:6]\n",
    "df_imp_completa['NCM_4'] = df_imp_completa['CO_NCM'].astype(str).str.zfill(8).str[0:4]\n",
    "df_orig_ncm_sh['CO_SH6_STR'] = df_orig_ncm_sh['CO_SH6'].astype(str).str.zfill(6).str[0:6]\n",
    "df_orig_ncm_sh['CO_SH4_STR'] = df_orig_ncm_sh['CO_SH4'].astype(str).str.zfill(4).str[0:4]\n",
    "df_ncm_sh_4 = df_orig_ncm_sh[['CO_SH4_STR','NO_SH4_POR']]\n",
    "df_ncm_sh_4 = df_ncm_sh_4.groupby(['CO_SH4_STR','NO_SH4_POR']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "def analise_participacao_acumulada (df_param, limiar, s_nome_da_categoria, df_nomes, \n",
    "                                    plotar=False, itens_grafico=8):\n",
    "    \"\"\" Função para calcular as participações e encontrar a quantidade de itens para atingir o limiar\n",
    "        Plota o gráfico de participação de cada item no conjunto e da participação acumulada\n",
    "        Recebe como parâmetro o dataframe com os valores (df_param) e os nomes dos itens (df_nomes),\n",
    "          além do limiar desejado e parâmetros para o gráfico, de forma a\n",
    "          permitir a utilização da função de forma genérica para diferentes tipos de análise\n",
    "    \"\"\"\n",
    "    df_param.columns = ['valores']\n",
    "    df_param = df_param.sort_values(by=['valores'], ascending=False)\n",
    "    total = df_param.sum().values[0]\n",
    "    df_param['Participacao Acumulada'] = 100 * (df_param.cumsum()/df_param.sum())\n",
    "    df_param['eixo_x'] = np.arange(0,df_param.shape[0])\n",
    "    df_param['Participacao Individual'] = 100 * (df_param['valores']/total)\n",
    "    df_param = df_param.reset_index()\n",
    "    df_param.columns = ['Item da classe', 'valores','Participacao Acumulada','eixo_x', \n",
    "                        'Participacao Individual' ]\n",
    "    df_limiar = df_param[df_param['Participacao Acumulada']<=limiar]\n",
    "    pontos = df_limiar.shape[0]\n",
    "    \n",
    "    # Plota gráfico da participação de cada item no total, assim como a participação acumulada\n",
    "    if plotar:\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        qtd_it = pd.Series([itens_grafico,df_param.shape[0]]).min()\n",
    "        i_item = 0\n",
    "        y_lb = []\n",
    "        df_nomes.columns=['codigo','nome']\n",
    "        for p in np.arange(0,qtd_it):\n",
    "            item_classe = df_param['Item da classe'][i_item]\n",
    "            nome_item = df_nomes['nome'].loc[df_nomes['codigo'] == item_classe].values[0]\n",
    "            nome_item = nome_item[:40]\n",
    "            y_lb.append(nome_item)\n",
    "            i_item = i_item +1\n",
    "   \n",
    "        plt.bar([ label.replace(' ', '\\n') for label in y_lb ],\n",
    "                df_param['Participacao Individual'].head(qtd_it))\n",
    "        plt.ylabel ( 'Participação do item no conjunto (%)'  )\n",
    "        plt.xticks(rotation=30, ha=\"right\", va='top', fontsize=11, wrap=True)\n",
    "        titulo = (f'Participação dos principais itens da coluna {s_nome_da_categoria} '\n",
    "                f'no valor total FOB\\n')\n",
    "        titulo=titulo + f'Para o limiar de {limiar}% de participação são necessários {pontos} itens\\n'\n",
    "        titulo=titulo + f'(período de {ANALISES_ANO_INICIAL} a {ANALISES_ANO_FINAL})'\n",
    "        plt.title(titulo)\n",
    "        plt.tight_layout()\n",
    "        ax2 = plt.twinx()\n",
    "        ax2.spines['right'].set_position(('axes', 1.0))\n",
    "        ax2.set_ylabel(ylabel='Participação acumulada (%)', fontsize=11)\n",
    "        df_param['Participacao Acumulada'].head(itens_grafico).plot(ax=ax2, color='r', linewidth='2')\n",
    "\n",
    "    # retorna o dataframe df_limiar (que contém apenas os itens dentro do limiar)\n",
    "    #  e o dataframe df_param, que contém todos os itens da categoria\n",
    "    return df_limiar, df_param\n",
    "\n",
    "\n",
    "# Compara as participações dos países no valor FOB total de importações\n",
    "# Item 4.3.1 do TCC\n",
    "# -----------------\n",
    "df_red_pais, df_comp_pais = analise_participacao_acumulada ( \n",
    "    df_imp_completa.groupby(['CO_PAIS']).agg({'VL_FOB': ['sum']}) , \n",
    "    LIMIAR_PAISES, 'CO_PAIS (país de origem das mercadorias)', \n",
    "    df_orig_pais[['CO_PAIS','NO_PAIS']], True,10)\n",
    "\n",
    "# Compara as participações das unidades da RFB de desembarque no valor FOB total de importações\n",
    "# Item 4.3.2 do TCC\n",
    "# -----------------\n",
    "df_orig_urf['NO_URF_nome'] = df_orig_urf['NO_URF'].str.split('- ').str[1]\n",
    "df_red_urf, df_comp_urf = analise_participacao_acumulada ( \n",
    "    df_imp_completa.groupby(['CO_URF']).agg({'VL_FOB': ['sum']}) , \n",
    "    LIMIAR_URF, 'CO_URF (unidades da Receita Federal de desembarque)', \n",
    "    df_orig_urf[['CO_URF','NO_URF_nome']], True,10)\n",
    "\n",
    "# Compara as participações das vias de transporte no valor FOB total de importações\n",
    "# Item 4.3.3 do TCC\n",
    "# -----------------\n",
    "df_red_via, df_comp_via = analise_participacao_acumulada ( \n",
    "    df_imp_completa.groupby(['CO_VIA']).agg({'VL_FOB': ['sum']}) , \n",
    "    LIMIAR_VIA, 'CO_VIA (vias de transporte)', df_orig_via[['CO_VIA','NO_VIA']], True,8)\n",
    "\n",
    "# Compara as participações das unidades da federação de destino no valor FOB total de importações\n",
    "# Item 4.3.4 do TCC\n",
    "# -----------------\n",
    "df_red_uf, df_comp_uf = analise_participacao_acumulada ( \n",
    "    df_imp_completa.groupby(['SG_UF_NCM']).agg({'VL_FOB': ['sum']}) , \n",
    "    LIMIAR_UF, 'SG_UF_NCM (unidades da federação de destino)', \n",
    "    df_orig_uf[['SG_UF','SG_UF']], True,20)\n",
    "\n",
    "\n",
    "# Compara as participações dos tipos de mercadoria no valor FOB total de importações\n",
    "#  considera NCM representada por subitem (8 dígitos), subposição (6 dígitos) e posição (4 dígitos)\n",
    "# Item 4.3.5 do TCC\n",
    "# -----------------\n",
    "df_red_ncm, df_comp_ncm = analise_participacao_acumulada ( \n",
    "    df_imp_completa.groupby(['CO_NCM']).agg({'VL_FOB': ['sum']}) , \n",
    "    LIMIAR_NCM, 'NCM - subitem (CO_NCM)', df_orig_ncm[['CO_NCM','NO_NCM_POR']], True, 8)\n",
    "\n",
    "df_red_ncm_6, df_comp_ncm_6 = analise_participacao_acumulada ( \n",
    "    df_imp_completa.groupby(['NCM_6']).agg({'VL_FOB': ['sum']}) , \n",
    "    LIMIAR_NCM, 'NCM - subposição (6 primeiros dígitos da NCM)', \n",
    "    df_orig_ncm_sh[['CO_SH6_STR','NO_SH6_POR']], True, 8)\n",
    "\n",
    "df_red_ncm_4, df_comp_ncm_4 = analise_participacao_acumulada ( \n",
    "    df_imp_completa.groupby(['NCM_4']).agg({'VL_FOB': ['sum']}) , \n",
    "    LIMIAR_NCM, 'NCM - posição (4 primeiros dígitos da NCM)', \n",
    "    df_orig_ncm_sh[['CO_SH4_STR','NO_SH4_POR']], True, 8)\n",
    "\n",
    "\n",
    "# Armazena as listas de itens para o processamento do dataset \n",
    "#  (para a primeira fase de montagem do modelo preditivo - p1)\n",
    "#  (baseado no limiar de 80% de participação das variáveis)\n",
    "p1_lista_modelo = Lista_Param_Modelo()\n",
    "# Lista com os itens para atingir o limiar de 80%\n",
    "p1_lista_modelo.l_co_pais = list(df_red_pais['Item da classe'])\n",
    "p1_lista_modelo.l_co_urf = list(df_red_urf['Item da classe'])\n",
    "p1_lista_modelo.l_co_via = list(df_red_via['Item da classe'])\n",
    "p1_lista_modelo.l_sg_uf_ncm = list(df_red_uf['Item da classe'])\n",
    "if 'ND' in p1_lista_modelo.l_sg_uf_ncm: p1_lista_modelo.l_sg_uf_ncm.remove('ND')\n",
    "if 'EX' in p1_lista_modelo.l_sg_uf_ncm: p1_lista_modelo.l_sg_uf_ncm.remove('EX')\n",
    "if 'ZN' in p1_lista_modelo.l_sg_uf_ncm: p1_lista_modelo.l_sg_uf_ncm.remove('ZN')\n",
    "p1_lista_modelo.l_ncm_6 = list(df_red_ncm_6['Item da classe'])\n",
    "p1_lista_modelo.l_ncm_4 = list(df_red_ncm_4['Item da classe'])\n",
    "p1_lista_modelo.l_ncm = list(df_red_ncm['Item da classe'])\n",
    "# Lista completa dos itens, para testes do modelo\n",
    "p1_lista_modelo.l_completa_co_pais = list(df_comp_pais['Item da classe'])\n",
    "p1_lista_modelo.l_completa_co_urf = list(df_comp_urf['Item da classe'])\n",
    "p1_lista_modelo.l_completa_co_via = list(df_comp_via['Item da classe'])\n",
    "p1_lista_modelo.l_completa_sg_uf_ncm = list(df_comp_uf['Item da classe'])\n",
    "if 'ND' in p1_lista_modelo.l_completa_sg_uf_ncm: p1_lista_modelo.l_completa_sg_uf_ncm.remove('ND')\n",
    "if 'EX' in p1_lista_modelo.l_completa_sg_uf_ncm: p1_lista_modelo.l_completa_sg_uf_ncm.remove('EX')\n",
    "if 'ZN' in p1_lista_modelo.l_completa_sg_uf_ncm: p1_lista_modelo.l_completa_sg_uf_ncm.remove('ZN')\n",
    "p1_lista_modelo.l_completa_ncm_6 = list(df_comp_ncm_6['Item da classe'])\n",
    "p1_lista_modelo.l_completa_ncm_4 = list(df_comp_ncm_4['Item da classe'])\n",
    "p1_lista_modelo.l_completa_ncm = list(df_comp_ncm['Item da classe'])\n",
    "p1_lista_modelo.lista_principais_unidades_RFB = [817800, 817700, 917800, 817600, 717600, 927800, \n",
    "                                                 927700, 727600, 1017700, 717800, 227600, 812051, \n",
    "                                                 227700, 417800, 327600]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analisa a influência das variáveis do modelo (país de origem, unidade da federação, NCM, etc)\n",
    "# no comportamento da variável-alvo (unidade de desembarque das mercadorias - CO_URF)\n",
    "# ITEM 4.4 do TCC\n",
    "# ---------------\n",
    "\n",
    "def analisa_relacao_colunas (df_lista,df_nomes_lista,df_nomes_barras,titulo_itens,titulo_barras):\n",
    "    \"\"\" Função para plotar gráfico de relação entre duas colunas de interesse no dataset,\n",
    "        fazendo a comparação da participação de cada item em relação ao valor FOB total\n",
    "    \"\"\"\n",
    "    df_nomes_lista.columns=['codigo','nome']\n",
    "    df_lista['ITENS'] = df_lista['ITENS'].map(df_nomes_lista.set_index('codigo')['nome'])\n",
    "    df_lista['ITENS'] = df_lista['ITENS'].str.replace(' ','\\n')\n",
    "    df_lista['ITENS'] = df_lista['ITENS'].str[0:40]\n",
    "    df_nomes_barras.columns=['codigo','nome']\n",
    "    df_lista['BARRAS'] = df_lista['BARRAS'].map(df_nomes_barras.set_index('codigo')['nome'])\n",
    "    df_lista = df_lista.rename({'VL_FOB': 'Valor FOB'}, axis=1)\n",
    "    df_gr_totais = df_lista.groupby(['ITENS','BARRAS']).agg({'Valor FOB': ['sum']})\n",
    "    df_gr_totais = df_gr_totais.unstack()\n",
    "    somas_paises = df_gr_totais.sum(axis=1) / 100\n",
    "    df_gr_totais = df_gr_totais.iloc[:,:].div(somas_paises, axis=0)\n",
    "\n",
    "    df_gr_totais.columns.names = [titulo_itens,'','']\n",
    "    \n",
    "    ax = df_gr_totais.plot(kind='bar',figsize=(12,6), xlabel=f'Item comparado: {titulo_barras}', \n",
    "                           ylabel = 'Participação % no total\\n(relativa a cada item comparado)');\n",
    "    plt.xticks(rotation=30, ha=\"right\", va='top', fontsize=11, wrap=True);\n",
    "    \n",
    "    \n",
    "# Avalia as relações entre os itens mais importantes das colunas PAIS DE ORIGEM e UNIDADE DA RFB\n",
    "# ITEM 4.4.1 do TCC\n",
    "# -----------------\n",
    "df_relacao = df_imp_completa[(df_imp_completa['CO_PAIS'].isin(p1_lista_modelo.l_co_pais[:6])) & \n",
    "                             (df_imp_completa['CO_URF'].isin(p1_lista_modelo.l_co_urf[:6]))]\n",
    "df_relacao = df_relacao.rename({'CO_PAIS': 'ITENS', 'CO_URF': 'BARRAS'}, axis=1)\n",
    "analisa_relacao_colunas (df_relacao, df_orig_pais[['CO_PAIS','NO_PAIS']], \n",
    "                         df_orig_urf[['CO_URF','NO_URF_nome']],\n",
    "                        'UNIDADE DA RFB DE DESEMBARQUE', 'País de origem')\n",
    "\n",
    "\n",
    "# Avalia as relações entre itens das colunas UNIDADE DA FEDERAÇÃO DESTINO e UNIDADE DA RFB\n",
    "# ITEM 4.4.2 do TCC\n",
    "# -----------------\n",
    "df_relacao = df_imp_completa[(df_imp_completa['SG_UF_NCM'].isin(p1_lista_modelo.l_sg_uf_ncm[:6])) & \n",
    "                             (df_imp_completa['CO_URF'].isin(p1_lista_modelo.l_co_urf[:6]))]\n",
    "df_relacao = df_relacao.rename({'SG_UF_NCM': 'ITENS', 'CO_URF': 'BARRAS'}, axis=1)\n",
    "analisa_relacao_colunas (df_relacao, df_orig_uf[['SG_UF','NO_UF']], \n",
    "                         df_orig_urf[['CO_URF','NO_URF_nome']],\n",
    "                        'UNIDADE DA RFB DE DESEMBARQUE', 'Unidade da federação de destino')\n",
    "\n",
    "\n",
    "# Avalia as relações entre os itens das colunas NCM (subitem, 8 dígitos) e UNIDADE DA RFB\n",
    "# ITEM 4.4.3 do TCC\n",
    "# -----------------\n",
    "df_relacao = df_imp_completa[(df_imp_completa['CO_NCM'].isin(p1_lista_modelo.l_ncm[:8])) & \n",
    "                             (df_imp_completa['CO_URF'].isin(p1_lista_modelo.l_co_urf[:6]))]\n",
    "df_relacao = df_relacao.rename({'CO_NCM': 'ITENS', 'CO_URF': 'BARRAS'}, axis=1)\n",
    "analisa_relacao_colunas (df_relacao, df_orig_ncm[['CO_NCM','NO_NCM_POR']], \n",
    "                         df_orig_urf[['CO_URF','NO_URF_nome']],\n",
    "                        'UNIDADE DA RFB DE DESEMBARQUE', 'NCM - Subitem (8 dígitos)')\n",
    "\n",
    "\n",
    "# Avalia as relações entre os itens mais importantes das colunas NCM (posição, 4 dígitos) e UNIDADE DA RFB\n",
    "# ITEM 4.4.3 do TCC\n",
    "# -----------------\n",
    "df_relacao = df_imp_completa[(df_imp_completa['NCM_4'].isin(p1_lista_modelo.l_ncm_4[:8])) & \n",
    "                             (df_imp_completa['CO_URF'].isin(p1_lista_modelo.l_co_urf[:6]))]\n",
    "df_relacao = df_relacao.rename({'NCM_4': 'ITENS', 'CO_URF': 'BARRAS'}, axis=1)\n",
    "analisa_relacao_colunas (df_relacao, df_ncm_sh_4[['CO_SH4_STR','NO_SH4_POR']], \n",
    "                         df_orig_urf[['CO_URF','NO_URF_nome']],\n",
    "                        'UNIDADE DA RFB DE DESEMBARQUE', 'NCM - Posição (4 dígitos)')\n",
    "\n",
    "del df_relacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparativo entre diferentes locais de desembarque, em função do país de origem\n",
    "# ITEM 4.4.1 do TCC\n",
    "# ---------------\n",
    "\n",
    "def plota_pie_chart_itens(df_relacao, n_itens, titulo):\n",
    "    \"\"\" Função para plotar gráfico \"pie-chart\" para comparação entre dois locais de desembarque\n",
    "    \"\"\"\n",
    "    df_princ_paises, df_todos_paises = analise_participacao_acumulada ( \n",
    "            df_relacao.groupby(['CO_PAIS']).agg({'VL_FOB': ['sum']}) , \n",
    "            LIMIAR_PAISES, 'CO_PAIS (país de origem das mercadorias)', \n",
    "            df_orig_pais[['CO_PAIS','NO_PAIS']], False,10)\n",
    "\n",
    "    df_nomes_lista = df_orig_pais[['CO_PAIS','NO_PAIS']]\n",
    "    df_nomes_lista.columns=['codigo','nome']\n",
    "    df_todos_paises['Item da classe'] = df_todos_paises['Item da classe'].map(df_nomes_lista.set_index('codigo')['nome'])\n",
    "    df_todos_paises = df_todos_paises.head(n_itens)\n",
    "    total_outros = 100 - df_todos_paises['Participacao Individual'].sum()\n",
    "    df_todos_paises.drop(['Participacao Acumulada','valores','eixo_x'], inplace=True, axis=1)\n",
    "    df_todos_paises.loc[df_todos_paises.shape[0]] = ['Outros',total_outros]\n",
    "    df_todos_paises.set_index('Item da classe',inplace=True)\n",
    "\n",
    "    expl = [0] * (n_itens+1)\n",
    "    expl[0] = 0.05\n",
    "    expl[1] = 0.025\n",
    "    cores = ['#ff7799','#66b3ff','#99ff99','#ffcc99','#88d355']\n",
    "    ax = df_todos_paises.plot(kind='pie',y='Participacao Individual', x=\"Item da classe\",\n",
    "                              autopct='%1.1f%%', colors=cores, figsize=(6, 6),  shadow=True, \n",
    "                              startangle=0, fontsize=14, legend=False, explode=expl)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title(titulo,fontsize= 14)\n",
    "\n",
    "# Compara o Aeroporto de Guarulhos e o Porto de São Sebastião em relação ao país de origem\n",
    "plota_pie_chart_itens( df_imp_completa[(df_imp_completa['CO_URF']==817700)],4,\n",
    "                      'Desembarque no Aeroporto de Guarulhos')\n",
    "plota_pie_chart_itens( df_imp_completa[(df_imp_completa['CO_URF']==812051)],4,\n",
    "                      'Desembarque no Porto de São Sebastião')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparativo entre tipos de mercadorias em algumas unidades de desembarque\n",
    "# ITEM 4.4.3 do TCC\n",
    "# ---------------\n",
    "\n",
    "def plota_tipos_mercadorias(df_relacao, n_itens, titulo):\n",
    "    \"\"\" Função para plotar gráfico dos tipos de mercadoria (NCM - posição 4 dígitos)\n",
    "            que predominam em um determinado local de desembarque\n",
    "    \"\"\"    \n",
    "    df_nomes_lista = df_ncm_sh_4[['CO_SH4_STR','NO_SH4_POR']]\n",
    "    df_princ_ncm, df_todas_ncm = analise_participacao_acumulada ( \n",
    "        df_relacao.groupby(['NCM_4']).agg({'VL_FOB': ['sum']}) , \n",
    "        LIMIAR_NCM, 'NCM', df_nomes_lista, False, 8)\n",
    "    df_nomes_lista.columns=['codigo','nome']\n",
    "    df_todas_ncm['Item da classe'] = df_todas_ncm['Item da classe'].map(df_nomes_lista.set_index('codigo')['nome'])\n",
    "    df_todas_ncm = df_todas_ncm.head(n_itens)\n",
    "    df_todas_ncm.drop(['Participacao Acumulada','valores','eixo_x'], \n",
    "                      inplace=True, axis=1)\n",
    "\n",
    "    df_todas_ncm.rename(columns = {'Item da classe': 'Principais tipos de mercadoria'},\n",
    "                        inplace=True)\n",
    "    df_todas_ncm.set_index('Principais tipos de mercadoria',inplace=True)\n",
    "    df_todas_ncm[\"Participacao Individual\"] = np.log10(df_todas_ncm[\"Participacao Individual\"]+1)\n",
    "    ax = df_todas_ncm.plot(kind=\"barh\", legend=False, width=0.8, figsize=(8,4), title = titulo)\n",
    "    for i, (p, pr) in enumerate(zip(df_todas_ncm.index, df_todas_ncm[\"Participacao Individual\"])):\n",
    "        posi_esp = p.find(' ',40,60)+1\n",
    "        p = p[0:posi_esp] + '\\n  ' + p[posi_esp:90]\n",
    "        plt.text(s=' ' + p, x=0, y=i, color=\"w\", verticalalignment=\"center\", size=12,\n",
    "                 horizontalalignment=\"left\", fontweight = 'bold')\n",
    "        \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Compara algumas unidades de desembarque em relação aos tipos de mercadoria predominantes\n",
    "plota_tipos_mercadorias( df_imp_completa[(df_imp_completa['CO_URF']==227700)],3,\n",
    "                        'Desembarque no Aeroporto de Manaus - AM')\n",
    "plota_tipos_mercadorias( df_imp_completa[(df_imp_completa['CO_URF']==417800)],3,\n",
    "                        'Desembarque no Porto de Suape - PE')\n",
    "plota_tipos_mercadorias( df_imp_completa[(df_imp_completa['CO_URF']==927800)],3,\n",
    "                        'Desembarque no Porto de Itajaí - SC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Prepara o dataset base para o modelo de aprendizado de máquina\n",
    "# Item 4.5 do TCC\n",
    "# ---------------\n",
    "\n",
    "if UTILIZAR_DATASET_BASE_PRE_GRAVADO:\n",
    "    if CARREGAR_DATASETS_DO_REPOSITORIO_NUVEM:\n",
    "        df_base = pd.read_csv('https://raw.githubusercontent.com/rogmac/TCC/main/datasets/DF_BASE.csv',\n",
    "                              sep=';', encoding='latin1')\n",
    "    else:\n",
    "        df_base = pd.read_csv(filepath_or_buffer=CAMINHO_DATASET_BASE_LOCAL,sep=';')\n",
    "else:\n",
    "    # Seleciona o período (ano inicial/final) para o dataset que alimentará o modelo preditivo\n",
    "    df_imp_completa = df_imp_completa[(df_imp_completa['CO_ANO'] >= MODELO_ANO_INICIAL) & \n",
    "                                      (df_imp_completa['CO_ANO'] <= MODELO_ANO_FINAL)]\n",
    "\n",
    "    # Seleciona amostras aleatórias, que vão formar o dataset de base para os modelos\n",
    "    np.random.seed(i_SEED)\n",
    "    indices = np.random.choice(df_imp_completa.shape[0], replace = False, \n",
    "                               size=AMOSTRAS_DATASET_BASE_PRE_GRAVADO)\n",
    "    df_base = df_imp_completa.iloc[indices]\n",
    "\n",
    "    if GRAVAR_DATASET_BASE:\n",
    "        df_base.to_csv(CAMINHO_DATASET_BASE_LOCAL, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Funções desenvolvidas para testes do modelo Decision Tree em diferentes condições\n",
    "# Item 5.4 do TCC\n",
    "# ---------------\n",
    "\n",
    "def intervalo_acc(results, imprimir=False):\n",
    "    \"\"\" Função para calcular a acurácia (média e intervalo) considerando um conjunto\n",
    "        de testes que foram realizados pela função cross_val_score (validação cruzada)\n",
    "        A função retorna a média das acurácias dos testes\n",
    "    \"\"\"\n",
    "    media = results.mean()\n",
    "    dv = results.std()\n",
    "    if imprimir:\n",
    "        s_info = 'Validação cruzada: Acurácia média: {:.2f}%'.format(media*100)\n",
    "        s_info = s_info + ' -- Intervalo: [{:.2f}% ~ {:.2f}%]'.format((media - 2*dv)*100, \n",
    "                                                                      (media + 2*dv)*100)\n",
    "        print(s_info)\n",
    "    return media, dv\n",
    "\n",
    "def processa_modelos_DT ( df_imp_reclas, p_mod: Lista_Param_Modelo, comentario=''):\n",
    "    \"\"\" Função para realizar testes com o modelo preditivo Decision Tree\n",
    "        Os diversos parâmetros (que fazem parte da classe Lista_Modelo) definem as \n",
    "          diversas opções de montagem do dataset e do modelo para avaliação dos resultados\n",
    "    \"\"\"\n",
    "    # Seleciona amostras aleatórias a partir do dataset geral\n",
    "    np.random.seed(i_SEED)\n",
    "    indices = np.random.choice(df_imp_reclas.shape[0], replace = False, size=p_mod.qtd_amostras)\n",
    "    df_imp_reclas = df_imp_reclas.iloc[indices]\n",
    "\n",
    "    # Reclassifica os itens de menor relevância (na participação estatística) para \"outros\"\n",
    "    df_imp_reclas.loc[~df_imp_reclas['CO_URF'].isin(p_mod.l_co_urf), 'CO_URF'] = 'OUTRAS_URF'\n",
    "    df_imp_reclas.loc[~df_imp_reclas['CO_PAIS'].isin(p_mod.l_co_pais), 'CO_PAIS'] = 'OUTROS_PAISES'\n",
    "    df_imp_reclas.loc[~df_imp_reclas['CO_VIA'].isin(p_mod.l_co_via), 'CO_VIA'] = 'OUTRAS_VIAS'\n",
    "    df_imp_reclas.loc[~df_imp_reclas['SG_UF_NCM'].isin(p_mod.l_sg_uf_ncm), 'SG_UF_NCM'] = 'OUTRAS_UF'\n",
    "    df_imp_reclas.loc[~df_imp_reclas['NCM_6'].isin(p_mod.l_ncm_6), 'NCM_6'] = 'OUTRAS_NCM_6'\n",
    "    df_imp_reclas.loc[~df_imp_reclas['NCM_4'].isin(p_mod.l_ncm_4), 'NCM_4'] = 'OUTRAS_NCM_4'\n",
    "    df_imp_reclas.loc[~df_imp_reclas['CO_NCM'].isin(p_mod.l_ncm), 'CO_NCM'] = 'OUTRAS_NCM'\n",
    "    \n",
    "    # ajusta os nomes das colunas e remove aquelas que não serão utilizadas no modelo\n",
    "    if p_mod.opcao_NCM == 8: df_imp_reclas['NCM_MOD'] = df_imp_reclas['CO_NCM']\n",
    "    elif p_mod.opcao_NCM == 6: df_imp_reclas['NCM_MOD'] = df_imp_reclas['NCM_6']\n",
    "    else: df_imp_reclas['NCM_MOD'] = df_imp_reclas['NCM_4']\n",
    "    df_imp_reclas = df_imp_reclas.drop(['CO_ANO', 'CO_NCM','NCM_6', 'NCM_4'], axis=1)\n",
    "   \n",
    "    # Prepara os dataframes de treinamento e teste, criando as colunas \"dummies\"\n",
    "    df_m_dum = pd.get_dummies(df_imp_reclas, columns=['CO_MES', 'CO_PAIS','SG_UF_NCM',\n",
    "                                                      'CO_VIA','NCM_MOD','CO_URF'], \n",
    "                         prefix=['CO_MES', 'CO_PAIS','SG_UF_NCM','CO_VIA','NCM_MOD','CO_URF'])\n",
    "\n",
    "    # Imprime parâmetros, caso desejado  \n",
    "    if (p_mod.imprimir_parametros | p_mod.imprimir_resultados):\n",
    "        print(f'Teste do modelo DecisionTree - versão {p_mod.versao} ({comentario})')\n",
    "    if p_mod.imprimir_parametros:\n",
    "        print(f'     Itens para cada coluna: CO_PAIS: {len(p_mod.l_co_pais)}, '\n",
    "              f'CO_URF: {len(p_mod.l_co_urf)}, CO_VIA: {len(p_mod.l_co_via)}, '\n",
    "              f'SG_UF_NCM: {len(p_mod.l_sg_uf_ncm)}')\n",
    "        if p_mod.opcao_NCM == 8: print(f'     Quantidade de NCM (subitem 8 dígitos): {len(p_mod.l_ncm)}')\n",
    "        elif p_mod.opcao_NCM == 6: print(f'     Quantidade de NCM '\n",
    "                                         f'(subposição 6 dígitos): {len(p_mod.l_ncm_6)}')\n",
    "        else: print(f'     Quantidade de NCM (posição 4 dígitos): {len(p_mod.l_ncm_4)}')\n",
    "        print(f'     Quantidade amostras: {p_mod.qtd_amostras}, Proporção teste: {p_mod.proporcao_teste}')\n",
    "        print(f'     Quantidade de colunas do dataset (incluindo dummies): {df_m_dum.shape[1]}')\n",
    "    \n",
    "    # Separa as colunas que fazem parte de X (variáveis do modelo) e y (variável alvo)\n",
    "    #   X contém todas as variáveis, menos a variável-alvo; y contém as colunas da variável-alvo\n",
    "    df_X = df_m_dum[df_m_dum.columns[~pd.Series(df_m_dum.columns).str.startswith('CO_URF')]]\n",
    "    df_y = df_m_dum[df_m_dum.columns[pd.Series(df_m_dum.columns).str.startswith('CO_URF')]]\n",
    "\n",
    "    # Prepara o conjunto de treinamento e o conjunto de teste\n",
    "    X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(df_X, df_y, \n",
    "                                        test_size = p_mod.proporcao_teste, random_state = i_SEED)\n",
    "\n",
    "    # Inicializa o modelo preditivo a ser testado\n",
    "    ml_modelo = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth = 5, \n",
    "                                       min_samples_split = 2, random_state = i_SEED)\n",
    "\n",
    "    if p_mod.otimizar_com_grid_search:\n",
    "        # otimiza o modelo antes\n",
    "        param_dict = { 'criterion':['gini','entropy'], 'max_depth':range(1,10), \n",
    "                      'min_samples_split':range(1,10), 'min_samples_leaf':range(1,5) }\n",
    "        grid = GridSearchCV (ml_modelo, param_grid=param_dict, cv=10, verbose=0, n_jobs=-1)\n",
    "        grid.fit(X_treinamento, y_treinamento)\n",
    "        print(f'      Resultado GridSearchCV: {grid.best_params_}')\n",
    "        ml_modelo = grid.best_estimator_\n",
    "\n",
    "    # Prepara a validação cruzada\n",
    "    np.random.seed(i_SEED)\n",
    "    cv = KFold(n_splits = 5, shuffle = True)\n",
    "    results = cross_val_score(ml_modelo, X_treinamento, y_treinamento, cv = cv, scoring = 'accuracy')\n",
    "    acc_media_cross_val, acc_dv_cross_val = intervalo_acc(results, p_mod.imprimir_resultados)\n",
    "\n",
    "    # Roda o modelo preditivo com os dados de teste\n",
    "    start_time = time.time()\n",
    "    ml_modelo.fit(X_treinamento, y_treinamento)\n",
    "    total_time = time.time() - start_time\n",
    "    y_pred = ml_modelo.predict(X_teste)\n",
    "\n",
    "    # Avalia os resultados\n",
    "    linhas_corretas = y_teste.eq(y_pred).all(axis=1).sum()\n",
    "    total_linhas = y_pred.shape[0]\n",
    "    percentual = 100*(linhas_corretas/total_linhas)\n",
    "   \n",
    "    if p_mod.imprimir_resultados:\n",
    "        print(f'Predição sobre amostras de teste: {linhas_corretas} acertos em {total_linhas} '\n",
    "              f'({percentual:.2f}%) (treinamento com {X_treinamento.shape[0]})')\n",
    "        print(f'Tempo para treinamento: {1000 * total_time:.3f} ms')\n",
    "\n",
    "    return acc_media_cross_val, ml_modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.1.1\n",
    "# considera a quantidade de itens para cada variável de forma a atingir 80% de participação no valor total\n",
    "# (dados obtidos na execução do item 4.3)\n",
    "# Item 5.4.1 do TCC\n",
    "# -----------------\n",
    "\n",
    "p1_lista_modelo.l_co_urf = p1_lista_modelo.lista_principais_unidades_RFB\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "df_temp = df_base.copy()\n",
    "param.versao = '1.1.1'\n",
    "param.opcao_NCM = 8\n",
    "param.imprimir_parametros = True\n",
    "param.imprimir_resultados = True\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, 'parâmetros obtidos no item 4.3 do TCC' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.2.X\n",
    "# Avalia o efeito do tratamento dos outliers\n",
    "# Item 5.4.2 do TCC\n",
    "# -----------------\n",
    "\n",
    "# primeira abordagem - nenhum tratamento para outliers\n",
    "df_temp = df_base.copy()\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.versao = '1.2.1'\n",
    "param.opcao_NCM = 8\n",
    "param.imprimir_parametros = False\n",
    "param.imprimir_resultados = True\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, '1 - nenhum tratamento para outliers' )\n",
    "\n",
    "# segunda abordagem\n",
    "#  substitui VL_FOB e KG_LIQUIDO pelo limite superior calculado (para outliers acima do limite) e \n",
    "#  substitui VL_FOB e KG_LIQUIDO pelo primeiro quartil (para outliers abaixo do primeiro quartil)\n",
    "df_temp = df_base.copy()\n",
    "param.versao = '1.2.2'\n",
    "# VL_FOB\n",
    "Q1=df_temp['VL_FOB'].quantile(0.25)\n",
    "Q3=df_temp['VL_FOB'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "df_temp['VL_FOB'][df_temp['VL_FOB']>lim_sup] = lim_sup\n",
    "df_temp['VL_FOB'][df_temp['VL_FOB']<Q1] = Q1\n",
    "# LG_LIQUIDO\n",
    "Q1=df_temp['KG_LIQUIDO'].quantile(0.25)\n",
    "Q3=df_temp['KG_LIQUIDO'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "df_temp['KG_LIQUIDO'][df_temp['KG_LIQUIDO']>lim_sup] = lim_sup\n",
    "df_temp['KG_LIQUIDO'][df_temp['KG_LIQUIDO']<Q1] = Q1\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, '2 - aplica limites' )\n",
    "\n",
    "# terceira abordagem\n",
    "#  substitui VL_FOB e KG_LIQUIDO pelo limite superior calculado (para outliers acima do limite) e \n",
    "#  remove outliers abaixo do primeiro quartil\n",
    "df_temp = df_base.copy()\n",
    "param.versao = '1.2.3'\n",
    "# VL_FOB\n",
    "Q1=df_temp['VL_FOB'].quantile(0.25)\n",
    "Q3=df_temp['VL_FOB'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "df_temp['VL_FOB'][df_temp['VL_FOB']>lim_sup] = lim_sup\n",
    "df_temp = df_temp[df_temp['VL_FOB']>=Q1]\n",
    "# KG_LIQUIDO\n",
    "Q1=df_temp['KG_LIQUIDO'].quantile(0.25)\n",
    "Q3=df_temp['KG_LIQUIDO'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "df_temp['KG_LIQUIDO'][df_temp['KG_LIQUIDO']>lim_sup] = lim_sup\n",
    "df_temp = df_temp[df_temp['KG_LIQUIDO']>=Q1]\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, \n",
    "                                       '3 - aplica limite superior e remove inferiores' )\n",
    "\n",
    "\n",
    "# quarta abrodagem\n",
    "df_temp = df_base.copy()\n",
    "param.versao = '1.2.4'\n",
    "Q1=df_temp['VL_FOB'].quantile(0.25)\n",
    "Q3=df_temp['VL_FOB'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "# separa os outliers\n",
    "df_outliers = df_temp[df_temp['VL_FOB']>lim_sup]\n",
    "df_temp = df_temp[df_temp['VL_FOB']<=lim_sup]\n",
    "# redistribui os outliers, gerando n linhas para cada outlier\n",
    "#  onde n é a divisão inteira (ceiling) entre o valor FOB e o limite superior\n",
    "df_outliers['fator'] = ((df_outliers['VL_FOB'] // lim_sup) + 1).astype(int)\n",
    "df_outliers['VL_FOB'] = df_outliers['VL_FOB'] / df_outliers['fator']\n",
    "df_outliers['KG_LIQUIDO'] = df_outliers['KG_LIQUIDO'] / df_outliers['fator']\n",
    "df_outliers = df_outliers.loc[df_outliers.index.repeat(df_outliers['fator'])].reset_index(drop=True)\n",
    "df_outliers.drop(['fator'], axis=1, inplace=True)\n",
    "df_temp = pd.concat([df_temp,df_outliers], axis=0)\n",
    "\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, '4 - redistribui os outliers em linhas' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.2.1\n",
    "# Substitui a variável NCM subitem (8 dígitos) por NCM posição (4 dígitos)\n",
    "# Item 5.4.3 do TCC\n",
    "# -----------------\n",
    "\n",
    "df_temp = df_base.copy()                         \n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.versao = '1.2.1'\n",
    "param.opcao_NCM = 4\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, \n",
    "                                       'substitui subitem (8 dig) por posição (4 dig) na NCM' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.3.1\n",
    "# Adiciona as principais vias de transporte no modelo (CO_VIA - marítima, aérea, terrestre)\n",
    "# Item 5.4.4 do TCC\n",
    "# -----------------\n",
    "\n",
    "df_temp = df_base.copy()      \n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.versao = '1.3.1'\n",
    "param.l_co_via = param.l_completa_co_via[0:3]\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, 'adiciona as principais vias de transporte' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.4.1\n",
    "# Adiciona todas as unidades da federação de destino, para comparação\n",
    "# Item 5.4.5 do TCC\n",
    "# -----------------\n",
    "\n",
    "df_temp = df_base.copy()       \n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.versao = '1.4.1'\n",
    "param.l_sg_uf_ncm = param.l_completa_sg_uf_ncm\n",
    "if 'ND' in param.l_sg_uf_ncm: param.l_sg_uf_ncm.remove('ND')\n",
    "if 'EX' in param.l_sg_uf_ncm: param.l_sg_uf_ncm.remove('EX')\n",
    "if 'ZN' in param.l_sg_uf_ncm: param.l_sg_uf_ncm.remove('ZN')\n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, 'adiciona as demais unidades da federação')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.5.X\n",
    "# Avalia influência da quantidade de países (coluna CO_PAIS)\n",
    "# Item 5.4.6 do TCC\n",
    "# -----------------\n",
    "\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.imprimir_parametros = False\n",
    "param.imprimir_resultados = False\n",
    "pos_v = 1\n",
    "acc_m=[]\n",
    "faixa = np.arange(10,80,2)\n",
    "for valor in faixa:\n",
    "    df_temp = df_base.copy()                 \n",
    "    param.l_co_pais = param.l_completa_co_pais[0:valor]\n",
    "    param.versao = f'1.5.{pos_v}'\n",
    "    acc_m.append(processa_modelos_DT(df_temp, param, f'influência da quantidade de países: {valor}'))\n",
    "    pos_v = pos_v+1\n",
    "\n",
    "# plota gráfico para avaliação da variação da acurácia em função da quantidade de itens na coluna\n",
    "res_acc= pd.DataFrame (acc_m, faixa)\n",
    "res_acc.plot(figsize=(8,4), ylabel='Acurácia média na validação cruzada', \n",
    "             xlabel='Quantidade de países (CO_PAIS)',\n",
    "             title = 'Influência da quantidade de países no resultado do modelo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.6.X\n",
    "# Avalia influência da quantidade de itens de NCM (posição com 4 dígitos)\n",
    "# Item 5.4.7 do TCC\n",
    "# -----------------\n",
    "\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.imprimir_parametros = False\n",
    "param.imprimir_resultados = False\n",
    "param.opcao_NCM = 4\n",
    "pos_v = 1\n",
    "acc_m=[]\n",
    "faixa = np.arange(5,500,20)\n",
    "for valor in faixa:\n",
    "    df_temp = df_base.copy()                 \n",
    "    param.versao = f'1.6.{pos_v}'\n",
    "    param.l_ncm_4 = param.l_completa_ncm_4[0:valor]\n",
    "    acc_m.append(processa_modelos_DT (df_temp, param, f'influência da quantidade de NCM: {valor}' ))\n",
    "    pos_v = pos_v+1\n",
    "\n",
    "# plota gráfico para avaliação da variação da acurácia em função da quantidade de itens na coluna\n",
    "res_acc= pd.DataFrame (acc_m, faixa)\n",
    "res_acc.plot(figsize=(8,4), ylabel='Acurácia média na validação cruzada', \n",
    "             xlabel='Quantidade de NCM (posição - 4 dígitos)',\n",
    "             title = 'Influência da quantidade de itens NCM no resultado do modelo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Teste do modelo preditivo Decision Tree - Versão 1.7.X\n",
    "# Avalia influência da quantidade de amostras a serem extraídas\n",
    "# Item 5.4.8 do TCC\n",
    "# -----------------\n",
    "\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.imprimir_parametros = False\n",
    "param.imprimir_resultados = False\n",
    "param.opcao_NCM = 4\n",
    "pos_v = 1\n",
    "acc_m=[]\n",
    "faixa = np.logspace(1, 5, 50).astype(int)\n",
    "for valor in faixa:\n",
    "    df_temp = df_base.copy()                 \n",
    "    param.versao = f'1.7.{pos_v}'\n",
    "    param.qtd_amostras = valor\n",
    "    acc_m.append(processa_modelos_DT(df_temp, param, f'influência da quantidade de amostras: {valor}'))\n",
    "    pos_v = pos_v+1\n",
    "\n",
    "# plota gráfico para avaliação da variação da acurácia em função da quantidade de amostras\n",
    "res_acc= pd.DataFrame (acc_m, faixa)\n",
    "fig = res_acc.plot(figsize=(8,4), ylabel='Acurácia média na validação cruzada', \n",
    "                   xlabel='Quantidade de amostras',\n",
    "                   title = 'Influência da quantidade de amostras no resultado do modelo');\n",
    "fig.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação dos melhores resultados ao modelo base-line\n",
    "# Item 5.4.9 do TCC\n",
    "# -----------------\n",
    "\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "df_temp = df_base.copy()\n",
    "param.versao = '2.1.1'\n",
    "param.imprimir_parametros = True\n",
    "param.imprimir_resultados = True\n",
    "\n",
    "# utiliza a NCM posição (dígitos)\n",
    "param.opcao_NCM = 4\n",
    "# acrescenta as vias de transporte principais\n",
    "param.l_co_via = param.l_completa_co_via[0:3]\n",
    "\n",
    "# passa número de amostras para 10 mil\n",
    "param.qtd_amostras = 10000\n",
    "p1_lista_modelo = deepcopy(param)\n",
    "   \n",
    "\n",
    "# quarta abrodagem para tratamento dos outliers\n",
    "df_temp = df_base.copy()\n",
    "param.versao = '1.2.4'\n",
    "Q1=df_temp['VL_FOB'].quantile(0.25)\n",
    "Q3=df_temp['VL_FOB'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lim_inf = Q1 - 1.5 * IQR \n",
    "lim_sup = Q3 + 1.5 * IQR\n",
    "# separa os outliers\n",
    "df_outliers = df_temp[df_temp['VL_FOB']>lim_sup]\n",
    "df_temp = df_temp[df_temp['VL_FOB']<=lim_sup]\n",
    "# redistribui os outliers, gerando n linhas para cada outlier\n",
    "#  onde n é a divisão inteira (ceiling) entre o valor FOB e o limite superior\n",
    "df_outliers['fator'] = ((df_outliers['VL_FOB'] // lim_sup) + 1).astype(int)\n",
    "df_outliers['VL_FOB'] = df_outliers['VL_FOB'] / df_outliers['fator']\n",
    "df_outliers['KG_LIQUIDO'] = df_outliers['KG_LIQUIDO'] / df_outliers['fator']\n",
    "df_outliers = df_outliers.loc[df_outliers.index.repeat(df_outliers['fator'])].reset_index(drop=True)\n",
    "df_outliers.drop(['fator'], axis=1, inplace=True)\n",
    "df_temp = pd.concat([df_temp,df_outliers], axis=0)\n",
    "# armazena o dataset processado\n",
    "df_base = df_temp.copy()\n",
    "        \n",
    "acc_media_cross = processa_modelos_DT (df_temp, param, 'uso das melhores estratégias identificadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimização dos hiperparâmetros utilizando GridSearchCV\n",
    "# Item 5.4.10 do TCC\n",
    "# ------------------\n",
    "\n",
    "param.imprimir_parametros = False\n",
    "param.otimizar_com_grid_search = True\n",
    "# guarda o modelo DecisionTree otimizado na variável ml_modelo_final_DT\n",
    "acc_media_cross, ml_modelo_final_DT=processa_modelos_DT(df_temp, param,'com otimização GridSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e teste do Modelo Random Forest Classifier\n",
    "# ITEM 5.5.1 do TCC\n",
    "# -----------------\n",
    "\n",
    "df_temp = df_base.copy()\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.qtd_amostras = 10000\n",
    "param.otimizar_com_grid_search = False\n",
    "\n",
    "# Seleciona amostras aleatórias, gerando um novo dataframe de trabalho\n",
    "np.random.seed(i_SEED)\n",
    "indices = np.random.choice(df_temp.shape[0], replace = False, size=param.qtd_amostras)\n",
    "df_temp = df_temp.iloc[indices]\n",
    "\n",
    "# Prepara o dataset para divisão das amostras entre treinamento e teste\n",
    "df_temp['FOB_KILO'] = df_temp['VL_FOB'] / df_temp['KG_LIQUIDO']\n",
    "df_temp['SG_UF_NCM'] = pd.factorize(df_temp['SG_UF_NCM'])[0] + 1\n",
    "df_temp = df_temp.drop(['CO_ANO','NCM_6','CO_NCM'], axis=1)\n",
    "df_temp.loc[~df_temp['CO_URF'].isin(p1_lista_modelo.l_co_urf), 'CO_URF'] = 111111\n",
    "df_X = df_temp[df_temp.columns[~pd.Series(df_temp.columns).str.startswith('CO_URF')]]\n",
    "df_y = df_temp[df_temp.columns[pd.Series(df_temp.columns).str.startswith('CO_URF')]]\n",
    "df_y = df_y.values.ravel()\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(df_X, df_y, test_size = 0.2, \n",
    "                                                                  random_state = i_SEED)\n",
    "\n",
    "# Prepara a validação cruzada\n",
    "np.random.seed(i_SEED)\n",
    "cv = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "ml_modelo_final_RF=RandomForestClassifier(n_estimators=1000)\n",
    "print('Teste do modelo Random Forest')\n",
    "\n",
    "results = cross_val_score(ml_modelo_final_RF, X_treinamento, y_treinamento, cv = cv, \n",
    "                          scoring = 'accuracy')\n",
    "acc_media_cross_val = intervalo_acc(results, True)\n",
    "\n",
    "# Roda o modelo preditivo com os dados de teste\n",
    "start_time = time.time()\n",
    "ml_modelo_final_RF.fit(X_treinamento, y_treinamento)\n",
    "total_time = time.time() - start_time\n",
    "y_pred = ml_modelo_final_RF.predict(X_teste)\n",
    "\n",
    "itens_corretos = (y_teste==y_pred).sum()\n",
    "total_itens = y_pred.shape[0]\n",
    "percentual = 100*(itens_corretos/total_itens)\n",
    "\n",
    "print(f'Predição sobre amostras de teste: {itens_corretos} acertos em {total_itens} ({percentual:.2f}%)'\n",
    "      f' (treinamento com {X_treinamento.shape[0]})')\n",
    "print(f'Tempo para treinamento: {1000 * total_time:.3f} ms')\n",
    "\n",
    "if param.otimizar_com_grid_search:\n",
    "    param_dict = { 'criterion':['gini','entropy'], 'n_estimators':[100,1000,10000,10000],\n",
    "                  'max_depth':range(7,10), 'min_samples_split':range(2,5), \n",
    "                  'min_samples_leaf':range(1,3), 'bootstrap':[True,False] }\n",
    "    grid = GridSearchCV (ml_modelo_final_RF, param_grid=param_dict, cv=10, verbose=0, n_jobs=-1)\n",
    "    grid.fit(X_treinamento, y_treinamento)\n",
    "    print(f'      Resultado GridSearchCV: {grid.best_params_}')\n",
    "    ml_modelo_final_RF = grid.best_estimator_\n",
    "\n",
    "    start_time = time.time()\n",
    "    ml_modelo_final_RF.fit(X_treinamento, y_treinamento)\n",
    "    total_time = time.time() - start_time\n",
    "    y_pred = ml_modelo_final_RF.predict(X_teste)\n",
    "\n",
    "    itens_corretos = (y_teste==y_pred).sum()\n",
    "    total_itens = y_pred.shape[0]\n",
    "    percentual = 100*(itens_corretos/total_itens)\n",
    "\n",
    "    print(f'Resultados após otimização com GridSearchCV:')\n",
    "    print(f'   Predição sobre amostras de teste: {itens_corretos} acertos em {total_itens} '\n",
    "          f'({percentual:.2f}%) (treinamento com {X_treinamento.shape[0]})')\n",
    "    print(f'   Tempo para treinamento: {1000 * total_time:.3f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia importância das features utilizadas no modelo Random Forest\n",
    "# ITEM 5.5.2 do TCC\n",
    "# -----------------\n",
    "importancia = pd.DataFrame({'Variável': df_X.columns.values, \n",
    "                            'Importância (%)': 100 * ml_modelo_final_RF.feature_importances_})\n",
    "importancia.sort_values(by=['Importância (%)'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Naive Bayes (Categorical)\n",
    "# Item 5.6 do TCC\n",
    "# ---------------\n",
    "\n",
    "df_temp = df_base.copy()\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.qtd_amostras = 10000\n",
    "param.otimizar_com_grid_search = False\n",
    "\n",
    "# Seleciona amostras aleatórias, gerando um novo dataframe de trabalho\n",
    "np.random.seed(i_SEED)\n",
    "indices = np.random.choice(df_temp.shape[0], replace = False, size=10000)\n",
    "df_temp = df_temp.iloc[indices]\n",
    "\n",
    "# Prepara o dataset para divisão das amostras entre treinamento e teste\n",
    "df_temp.loc[~df_temp['CO_PAIS'].isin(p1_lista_modelo.l_co_pais), 'CO_PAIS'] = '9999'\n",
    "df_temp.loc[~df_temp['CO_VIA'].isin(p1_lista_modelo.l_co_via), 'CO_VIA'] = '9999'\n",
    "df_temp.loc[~df_temp['SG_UF_NCM'].isin(p1_lista_modelo.l_sg_uf_ncm), 'SG_UF_NCM'] = 'OUTRAS_UF'\n",
    "df_temp.loc[~df_temp['NCM_4'].isin(p1_lista_modelo.l_ncm_4), 'NCM_4'] = '999999'\n",
    "df_temp.loc[~df_temp['CO_URF'].isin(p1_lista_modelo.l_co_urf), 'CO_URF'] = 111111\n",
    "df_temp['SG_UF_NCM'] = pd.factorize(df_temp['SG_UF_NCM'])[0] + 1\n",
    "df_temp = df_temp.drop(['VL_FOB','KG_LIQUIDO'], axis=1)\n",
    "df_temp = df_temp.drop(['CO_ANO','NCM_6','CO_NCM'], axis=1)\n",
    "\n",
    "print('Teste do modelo Naive Bayes')\n",
    "\n",
    "df_X = df_temp[df_temp.columns[~pd.Series(df_temp.columns).str.startswith('CO_URF')]]\n",
    "df_y = df_temp[df_temp.columns[pd.Series(df_temp.columns).str.startswith('CO_URF')]]\n",
    "df_y = df_y.values.ravel()\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(df_X, df_y, test_size = 0.2, \n",
    "                                                                  random_state = i_SEED)\n",
    "\n",
    "# Prepara a validação cruzada\n",
    "np.random.seed(i_SEED)\n",
    "cv = KFold(n_splits = 5, shuffle = True)\n",
    "ml_modelo_final_NB = CategoricalNB(alpha = 0.1, fit_prior = False)\n",
    "ml_modelo_final_NB.fit(X_treinamento, y_treinamento)\n",
    "results = cross_val_score(ml_modelo_final_NB, X_treinamento, y_treinamento, cv = cv, \n",
    "                          scoring = 'accuracy')\n",
    "acc_media_cross_val = intervalo_acc(results, True)\n",
    "\n",
    "# Roda o modelo preditivo com os dados de teste\n",
    "start_time = time.time()\n",
    "ml_modelo_final_NB.fit(X_treinamento, y_treinamento)\n",
    "total_time = time.time() - start_time\n",
    "y_pred = ml_modelo_final_NB.predict(X_teste)\n",
    "\n",
    "itens_corretos = (y_teste==y_pred).sum()\n",
    "total_itens = y_pred.shape[0]\n",
    "percentual = 100*(itens_corretos/total_itens)\n",
    "print(f'Predição sobre amostras de teste: {itens_corretos} acertos em {total_itens} '\n",
    "      f'({percentual:.2f}%) (treinamento com {X_treinamento.shape[0]})')\n",
    "print(f'Tempo para treinamento: {1000 * total_time:.3f} ms')\n",
    "\n",
    "if param.otimizar_com_grid_search:\n",
    "    param_dict = { 'alpha':[0.1,1,1.5,2,2.5,3], \n",
    "                   'fit_prior':[True,False] }\n",
    "    grid = GridSearchCV (ml_modelo_final_NB, param_grid=param_dict, cv=10, verbose=0, n_jobs=-1)\n",
    "    grid.fit(X_treinamento, y_treinamento)\n",
    "    print(f'      Resultado GridSearchCV: {grid.best_params_}')\n",
    "    ml_modelo_final_NB = grid.best_estimator_\n",
    "\n",
    "    start_time = time.time()\n",
    "    ml_modelo_final_NB.fit(X_treinamento, y_treinamento)\n",
    "    total_time = time.time() - start_time\n",
    "    y_pred = ml_modelo_final_NB.predict(X_teste)\n",
    "\n",
    "    itens_corretos = (y_teste==y_pred).sum()\n",
    "    total_itens = y_pred.shape[0]\n",
    "    percentual = 100*(itens_corretos/total_itens)\n",
    "\n",
    "    print(f'Resultados após otimização com GridSearchCV:')\n",
    "    print(f'   Predição sobre amostras de teste: {itens_corretos} acertos em {total_itens} '\n",
    "          f'({percentual:.2f}%) (treinamento com {X_treinamento.shape[0]})')\n",
    "    print(f'   Tempo para treinamento: {1000 * total_time:.3f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação de erros e acertos do Random Forest Classifier\n",
    "# Analisa cada local de desembarque com mapa de calor\n",
    "# ITEM 5.7 do TCC\n",
    "# ---------------\n",
    "\n",
    "def amostragem_k_elementos(group, k=100):\n",
    "    if len(group) < k:\n",
    "        return group\n",
    "    return group.sample(k)\n",
    "\n",
    "df_temp = df_base.copy()\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.qtd_amostras = 10000\n",
    "param.otimizar_com_grid_search = False\n",
    "\n",
    "# balanceamento das amostras\n",
    "df_temp.loc[~df_temp['CO_URF'].isin(p1_lista_modelo.l_co_urf), 'CO_URF'] = 111111\n",
    "df_temp = df_temp.groupby('CO_URF').apply(amostragem_k_elementos, k=5000).reset_index(drop=True)\n",
    "df_temp.reset_index(inplace=True, drop=True)\n",
    "np.random.seed(i_SEED)\n",
    "indices = np.random.choice(df_temp.shape[0], replace = False, size=param.qtd_amostras)\n",
    "df_temp = df_temp.iloc[indices]\n",
    "\n",
    "# Prepara o dataset para divisão das amostras entre treinamento e teste\n",
    "df_temp['FOB_KILO'] = df_temp['VL_FOB'] / df_temp['KG_LIQUIDO']\n",
    "df_temp['SG_UF_NCM'] = pd.factorize(df_temp['SG_UF_NCM'])[0] + 1\n",
    "df_temp = df_temp.drop(['CO_ANO','NCM_6','CO_NCM'], axis=1)\n",
    "\n",
    "df_X = df_temp[df_temp.columns[~pd.Series(df_temp.columns).str.startswith('CO_URF')]]\n",
    "df_y = df_temp[df_temp.columns[pd.Series(df_temp.columns).str.startswith('CO_URF')]]\n",
    "df_y = df_y.values.ravel()\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(df_X, df_y, test_size = 0.2, \n",
    "                                                                  random_state = i_SEED)\n",
    "\n",
    "ml_modelo_final_RF=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Roda o modelo preditivo com os dados de teste\n",
    "start_time = time.time()\n",
    "ml_modelo_final_RF.fit(X_treinamento, y_treinamento)\n",
    "total_time = time.time() - start_time\n",
    "y_pred = ml_modelo_final_RF.predict(X_teste)\n",
    "\n",
    "itens_corretos = (y_teste==y_pred).sum()\n",
    "total_itens = y_pred.shape[0]\n",
    "percentual = 100*(itens_corretos/total_itens)\n",
    "\n",
    "print(f'Predição sobre amostras de teste: {itens_corretos} acertos em {total_itens}'\n",
    "      f' ({percentual:.2f}%)')\n",
    "\n",
    "# Prepara gráfico de calor para ilustrar os erros e acertos do modelo\n",
    "real = pd.Categorical(y_teste, categories=pd.Series(y_teste).unique(), ordered=False)\n",
    "predito = pd.Categorical(y_pred, categories=pd.Series(y_teste).unique(), ordered=False)\n",
    "cross_resultados = pd.crosstab(real, predito, rownames=['Real'], colnames=['Predição'], \n",
    "                               margins=False, dropna=False, normalize=False)\n",
    "fig, ax = plt.subplots(figsize=(10,7)) \n",
    "fig1 = sns.heatmap(cross_resultados,ax =ax, annot=True, fmt='d',cmap=\"vlag\",\n",
    "                   center = cross_resultados.max().max()/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo Random Forest com janela deslizante\n",
    "# Treinamento feito nos doze meses anteriores ao teste\n",
    "# Item 5.8 do TCC\n",
    "# ---------------\n",
    "\n",
    "df_temp = df_base.copy()\n",
    "param = deepcopy(p1_lista_modelo)\n",
    "param.qtd_amostras = 10000\n",
    "param.otimizar_com_grid_search = False\n",
    "\n",
    "# Prepara o dataset para divisão das amostras entre treinamento e teste\n",
    "df_temp.loc[~df_temp['CO_URF'].isin(p1_lista_modelo.l_co_urf), 'CO_URF'] = 111111\n",
    "df_temp['FOB_KILO'] = df_temp['VL_FOB'] / df_temp['KG_LIQUIDO']\n",
    "df_temp['SG_UF_NCM'] = pd.factorize(df_temp['SG_UF_NCM'])[0] + 1\n",
    "df_temp = df_temp.drop(['NCM_6','CO_NCM'], axis=1)\n",
    "\n",
    "ml_modelo_final_RF=RandomForestClassifier(n_estimators=1000)\n",
    "df_res_mes = pd.DataFrame(columns = ['mes','percentual'])\n",
    "for mes in np.arange(1,13):\n",
    "    # Treinamento será realizado com amostras de uma janela de 12 meses anterior ao mês de teste\n",
    "    df_Trein = df_temp[ ((df_temp['CO_ANO']==2018) & (df_temp['CO_MES']>=mes)) | \n",
    "                       ((df_temp['CO_ANO']==2019) & (df_temp['CO_MES']<mes))]\n",
    "    df_Trein = df_Trein.drop(['CO_ANO'], axis=1)\n",
    "    df_Trein.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    np.random.seed(i_SEED)\n",
    "    indices = np.random.choice(df_Trein.shape[0], replace = False, size=param.qtd_amostras)\n",
    "    df_Trein = df_Trein.iloc[indices]\n",
    "    df_Trein_X = df_Trein[df_Trein.columns[~pd.Series(df_Trein.columns).str.startswith('CO_URF')]]\n",
    "    df_Trein_y = df_Trein[df_Trein.columns[pd.Series(df_Trein.columns).str.startswith('CO_URF')]]\n",
    "    df_Trein_y = df_Trein_y.values.ravel()\n",
    "\n",
    "    # Roda o modelo preditivo com os dados de teste\n",
    "    start_time = time.time()\n",
    "    ml_modelo_final_RF.fit(df_Trein_X, df_Trein_y)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Teste será realizado com amostras do ano de 2019, de apenas um mês (posterior à janela de treino)\n",
    "    df_Teste = df_temp[ ((df_temp['CO_ANO']==2019) & (df_temp['CO_MES']==mes))]\n",
    "    df_Teste = df_Teste.drop(['CO_ANO'], axis=1)\n",
    "\n",
    "    np.random.seed(i_SEED)\n",
    "    indices = np.random.choice(df_Teste.shape[0], replace = False, size=param.qtd_amostras//4)\n",
    "    df_Teste = df_Teste.iloc[indices]\n",
    "    df_Teste_X = df_Teste[df_Teste.columns[~pd.Series(df_Teste.columns).str.startswith('CO_URF')]]\n",
    "    df_Teste_y = df_Teste[df_Teste.columns[pd.Series(df_Teste.columns).str.startswith('CO_URF')]]\n",
    "    df_Teste_y = df_Teste_y.values.ravel()\n",
    "\n",
    "    y_pred = ml_modelo_final_RF.predict(df_Teste_X)\n",
    "\n",
    "    itens_corretos = (df_Teste_y==y_pred).sum()\n",
    "    total_itens = y_pred.shape[0]\n",
    "    percentual = 100*(itens_corretos/total_itens)\n",
    "    df_res_mes = df_res_mes.append({'mes':calendar.month_abbr[mes], 'percentual':percentual}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "media_acertos = df_res_mes['percentual'].values.mean()\n",
    "titulo = f'Valor médio do percentual de acertos: {media_acertos:.2f}%'\n",
    "ax = df_res_mes.plot(kind='bar',x='mes', figsize=(8,2), title = titulo)\n",
    "r = ax.set_ylim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
